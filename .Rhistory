names
remain
remain1 = c(spades = 11, mades = 12, gades = 13)
remain1
str(remain1)
str(remain)
suits <- c("A", 12,"c", "d")
suits
class(remain)
class(remain1)
ls()
install.packages("ggplot2")
install.packages("matlib")
install.packages("rsample")
X=as.matrix(read.csv(file="X-data.csv",header = F))
library(readr)
y_1673241374123 <- read_csv("C:/Users/sanja/Downloads/y_1673241374123.csv")
View(y_1673241374123)
library(readr)
X_1673241366257 <- read_csv("C:/Users/sanja/Downloads/X_1673241366257.csv")
View(X_1673241366257)
library(readr)
time_1673241270748 <- read_csv("C:/Users/sanja/Downloads/time_1673241270748.csv")
View(time_1673241270748)
x
X
View(time_1673241270748)
View(time_1673241270748)
View(time_1673241270748)
View(X_1673241366257)
View(y_1673241374123)
X=as.matrix(read.csv(file="C:/Users/sanja/Downloads/y_1673241374123.csv",header = F))
colnames(X)<-c("X1","X2","X3","X4")
View(X)
View(X_1673241366257)
X=as.matrix(read.csv(file="C:/Users/sanja/Downloads/X_1673241366257.csv",header = F))
colnames(X)<-c("X1","X2","X3","X4")
X=as.matrix(read.csv(file="C:/Users/sanja/Downloads/X_1673241366257.csv",header = F))
colnames(X)<-c("X1","X2","X3","X4")
X=as.matrix(read.csv(file="C:/Users/sanja/Downloads/X_1673241366257.csv",header = F))
colnames(X)<-c("X1","X2","X3","X4")
View(y_1673241374123)
Y=as.matrix(read.csv(file="C:/Users/sanja/Downloads/y_1673241374123.csv",header = F))
colnames(Y)<-c("Y")
Time = read.csv("C:/Users/sanja/Downloads/time_1673241270748.csv", header = F, skip = 1)
Time = as.matrix(rbind(0, Time))
X.ts<-ts(X,start = c(min(Time),max(Time)),frequency =1)
Y.ts<-ts(Y,start = c(min(Time),max(Time)),frequency =1)
plot(X.ts,main = "Time series plot of X Signal", xlab = "Time", ylab = "Input signal")
plot(Y.ts,main = "Time series plot of Y Signal", xlab = "Time", ylab = "Output signal")
dis=density(X)
plot(dis,main = "Density plot of whole input signal")
dis=density(X)
plot(dis,main = "Density plot of whole input signal")
# Creating a Histrogram of X signal
hist(X,freq = FALSE,main = "DEn")
#Adding density in the histogram
lines(dis,lwd=2,col="red")
rug(jitter(X))
dis_X1=density(X[,"X1"])
hist(X[,"X1"],freq = FALSE,main = "Histogram and density plot of X1",xlab = "X1 Signal")
lines(dis_X1,lwd=2,col="red")
# Add the data-poins with noise in the X-axis
rug(jitter(X[,"X1"]))
dis_X2=density(X[,"X2"])
hist(X[,"X2"],freq = FALSE,main = "Histogram and density plot of X2",xlab = "X2 Signal")
lines(dis_X2,lwd=2,col="red")
rug(jitter(X[,"X2"]))
#Creating a density if X3 signal
dis_X3=density(X[,"X3"])
hist(X[,"X3"],freq = FALSE,main = "Histogram and density plot of X3",xlab = "X3 Signal")
lines(dis_X3,lwd=2,co
dis_X2=density(X[,"X2"])
hist(X[,"X2"],freq = FALSE,main = "Histogram and density plot of X2",xlab = "X2 Signal")
lines(dis_X2,lwd=2,col="red")
rug(jitter(X[,"X2"]))
#Creating a density if X3 signal
dis_X3=density(X[,"X3"])
hist(X[,"X3"],freq = FALSE,main = "Histogram and density plot of X3",xlab = "X3 Signal")
lines(dis_X3,lwd=2,col="red")
rug(jitter(X[,"X3"]))
dis_X4=density(X[,"X4"])
hist(X[,"X4"],freq = FALSE,main = "Histogram and density plot of X4",xlab = "X4 Signal")
lines(dis_X1,lwd=2,col="red")
rug(jitter(X[,"X4"]))
dis_y=density(Y)
plot(dis_y,main = "Density plot of Y",,xlab = "Output Signal")
hist(Y,freq = FALSE,main = "Histogram and density plot of Y",xlab = "Output Signal")
lines(dis_y,lwd=2,col="red")
rug(jitter(Y))
# Plotting X1 against Y
plot(X[,"X1"],Y,main = "Correlation betweeen X1 and Y signal", xlab = "X1 signal", ylab = "Output
signal" )
# Plotting X2 against Y
plot(X[,"X2"],Y,main = "Correlation betweeen X2 and Y signal", xlab = "X2 signal", ylab = "Output
signal")
# Plotting X3 against Y
plot(X[,"X3"],Y,main = "Correlation betweeen X3 and Y signal", xlab = "X3 signal", ylab = "Output
signal")
# Plotting X4 against Y
plot(X[,"X4"],Y,main = "Correlation betweeen X4 and Y signal", xlab = "X4 signal", ylab = "Output
signal")
# Calculating ones for binding the data
ones = matrix(1 , length(X)/4,1)
ones
#Calculating thetahat of Model 1
#Binding data from equation of model 1.
X_model1<-cbind(ones,(X[,"X4"]),(X[,"X1"])^2,(X[,"X1"])^3,(X[,"X3"])^4)
X_model1
#Calculating thetahat of model 1
Model1_thetahat=solve(t(X_model1) %*% X_model1) %*% t(X_model1) %*% Y
Model1_thetahat
#Binding data from equation of model 2.
X_model2<-cbind(ones,(X[,"X3"])^3,(X[,"X3"])^4)
X_model2
#Calculating thetahat of Model 2
Model2_thetahat=solve(t(X_model2) %*% X_model2) %*% t(X_model2) %*% Y
Model2_thetahat
#Binding data from equation of model 3.
X_model3<-cbind(ones,X[,"X2"],(X[,"X1"])^3,(X[,"X3"])^4)
X_model3
#Calculating thetahat of Model 3
Model3_thetahat=solve(t(X_model3) %*% X_model3) %*% t(X_model3) %*% Y
Model3_thetahat
#For model 4
#Binding data from equation of model 4.
X_model4<-cbind(ones,X[,"X4"],X[,"X1"]^3,X[,"X3"]^4)
X_model4
#Calculating thetahat of Model 4
Model4_thetahat=solve(t(X_model4) %*% X_model4) %*% t(X_model4) %*% Y
Model4_thetahat
#Binding data from equation of model 5.
X_model5<-cbind(ones,X[,"X4"],X[,"X1"]^2,X[,"X1"]^3,X[,"X3"]^4,X[,"X1"]^4)
X_model5
#Calculating thetahat of Model 5
Model5_thetahat=solve(t(X_model5) %*% X_model5) %*% t(X_model5) %*% Y
Model5_thetahat
#Calculating Y-hat and RSS Model 1
Y_hat_m1 = X_model1 %*% Model1_thetahat
Y_hat_m1
#Calculating RSS
RSS_Model_1=sum((Y-Y_hat_m1)^2)
RSS_Model_1
Y_hat_m2 = X_model2 %*% Model2_thetahat
Y_hat_m2
RSS_Model_2=sum((Y-Y_hat_m2)^2)
RSS_Model_2
Y_hat_m3 = X_model3 %*% Model3_thetahat
Y_hat_m3
RSS_Model_3=sum((Y-Y_hat_m3)^2)
RSS_Model_3
#Calculating Y-hat and RSS of model 4
Y_hat_m4 = X_model4 %*% Model4_thetahat
Y_hat_m4
RSS_Model_4=s
#Calculating Y-hat and RSS of model 4
Y_hat_m4 = X_model4 %*% Model4_thetahat
Y_hat_m4
RSS_Model_4=sum((Y-Y_hat_m4)^2)
RSS_Model_4
#Calculating Y-hat and RSS of model 5
Y_hat_m5 = X_model5 %*% Model5_thetahat
Y_hat_m5
RSS_Model_5=sum((Y-Y_hat_m5)^2)
RSS_Model_5
N=length(Y)
#Calculating the Variance of Model 1
Variance_model1=RSS_Model_1/(N-1)
Variance_model1
#Calculating the log-likelihood of Model 1
likehood_Model_1=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model1))-(1/(2*Variance_model1))*RSS_Model_1
likehood_Model_1
#Calculating Variance and log-likelihood of Model 2
Variance_model2=RSS_Model_2/(N-1)
Variance_model2
likehood_Model_2=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model2))-(1/(2*Variance_model2))*RSS_Model_2
likehood_Model_2
#Calculating Variance and log-likelihood of Model 3
Variance_model3=RSS_Model_3/(N-1)
Variance_model3
likehood_Model_3=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model3))-(1/(2*Variance_model3))*RSS_Model_3
likehood_Model_3
#Calculating Variance and log-likelihood of Model 4
Variance_model4=RSS_Model_4/(N-1)
Variance_model4
likehood_Model_4=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model4))-(1/(2*Variance_model4))*RSS_Model_4
likehood_Model_4
#Calculating Variance and log-likelihood of Model 5
Variance_model5=RSS_Model_5/(N-1)
Variance_model5
likehood_Model_5=
-(N/2)*(log(2*pi))-(N/2)*(log(Variance_model5))-(1/(2*Variance_model5))*RSS_Model_5
likehood_Model_5
##Calculating AIC and BIC of model 1
K_model1<-length(Model1_thetahat)
K_model1
AIC_model1=2*K_model1-2*likehood_Model_1
AIC_model1
BIC_model1=K_model1*log(N)-2*likehood_Model_1
BIC_model1
## thetahat of model 2
K_model2<-length(Model2_thetahat)
K_model2
##Calculating AIC and BIC of model 2
AIC_model2=2*K_model2-2*likehood_Model_2
AIC_model2
BIC_model2=K_model2*log(N)-2*likehood_Model_2
BIC_model2
## thetahat of model 3
K_model3<-length(Model3_thetahat)
K_model3
##Calculating AIC and BIC of model 3
AIC_model3=2*K_model3-2*likehood_Model_3
AIC_model3
BIC_model3=K_model3*log(N)-2*likehood_Model_3
BIC_model3
## thetahat of model 4
K_model4<-length(Model1_thetahat)
K_model4
##Calculating AIC and BIC of model 4
AIC_model4=2*K_model4-2*likehood_Model_4
AIC_model4
BIC_model4=K_model4*log(N)-2*likehood_Model_4
BIC_model4
## thetahat of model 5
K_model5<-length(Model5_thetahat)
K_model5
##Calculating AIC and BIC of model 5
AIC_model5=2*K_model5-2*likehood_Model_5
AIC_model5
BIC_model5=K_model5*log(N)-2*likehood_Model_5
BIC_model5
## Error of model1
model1_error <- Y-Y_hat_m1
## Plotting the graph QQplot and QQ line of model 1
qqnorm(model1_error, col = "darkcyan",main = "QQ plot of model 1")
qqline(model1_error, col = "red",lwd=1)
## Error of model2
model2_error <- Y-Y_hat_m2 # error of model 2
## Plotting QQplot and QQ line of model 2
qqnorm(model2_error, col = "darkcyan",main = "QQ plot of model 2")
qqline(model2_error, col = "red")
## Error of model2
model2_error <- Y-Y_hat_m2 # error of model 2
## Plotting QQplot and QQ line of model 2
qqnorm(model2_error, col = "darkcyan",main = "QQ plot of model 2")
qqline(model2_error, col = "red")
## Error of model3
model3_error <- Y- Y_hat_m3
## Plotting QQplot and QQ line of model 3
qqnorm(model3_error, col = "darkcyan",main = "QQ plot of model 3")
qqline(model3_error, col = "red")
## Error of model4
model4_error <- Y-Y_hat_m4
## Plotting QQplot and QQ line of model 4
qqnorm(model4_error, col = "darkcyan",main = "QQ plot of model 4")
qqline(model4_error, col = "red")
## Error of model5
model5_error <- Y- Y_hat_m5
## Plotting QQplot and QQ line of model 5
qqnorm(model5_error, col = "darkcyan",main = "QQ plot of model 5")
qqline(model5_error, col = "red")
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y<-initial_split(data = as.data.frame(Y),prop=.7)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=.7)
install.packages(tidymodels)
install.packages("tidymodels")
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=.7)
install.packages("tidymodels")
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=.7)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=3/4)
install.packages("ggplot2")
install.packages("matlib")
install.packages("rsample")
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=3/4)
install.packages("rsample")
set.seed(123)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split()
install.packages("ggplot2")
install.packages("matlib")
install.packages("rsample")
set.seed(123)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y =
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=3/4)
## Spliting the data of y into 2 form i.e. Traning and testing data set.
split_Y = initial_split(data = as.data.frame(Y),prop=3/4)
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rtools")
install.packages("Rtools")
install.packages(c("cli", "dplyr", "evaluate", "fansi", "forcats", "fs", "future", "knitr", "markdown", "Rcpp", "rmarkdown", "sass", "stringi", "tinytex", "utf8", "vroom", "xfun", "yaml"))
install.packages(c("cli", "dplyr", "evaluate", "fansi", "forcats", "fs", "future", "knitr", "markdown", "Rcpp", "rmarkdown", "sass", "stringi", "tinytex", "utf8", "vroom", "xfun", "yaml"))
#split data x
x_nrow = nrow(X_inputs)
#split data x
x_nrow = nrow(X_inputs)
#split data x
x_nrow = nrow(X)
#split data x
x_nrow = nrow(X)
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE) x_training_data <- X[x_splitIndex, ] x_testing_data <- X_inputs[-x_splitIndex, ]
#split data x
x_nrow = nrow(X)
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
x_training_data <- X[x_splitIndex, ] x_testing_data <- X_inputs[-x_splitIndex, ]
#split data x
x_nrow = nrow(X)
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
x_training_data <- X[x_splitIndex, ] x_testing_data <- X_inputs[-x_splitIndex, ]
#split data x
x_nrow = nrow(X)
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
x_training_data <- X[x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
x_training_data <- X[x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_training_data <- X [x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
x_training_data <- X [x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_training_data <- X[x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_training_data <- X[x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
x_plitINdex
x_plitIndex
x_splitIndex
x_nrow = nrow(X)
set.seed(123)x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
set.seed(123)
indexes <- sample(1:nrow(X), round(0.8 * nrow(X)))
# Split the data into training and testing datasets
training_data <- your_data[indexes, ]
testing_data <- your_data[-indexes, ]
# Split the data into training and testing datasets
training_data <- X[indexes, ]
testing_data <- X[-indexes, ]
x_splitIndex <- sample(1:nrow(X), round(0.8 * nrow(X)))
set.seed(123)
x_nrow = nrow(X)
x_splitIndex <- sample(1:nrow(X), round(0.8 * nrow(X)))
# Split the data into training and testing datasets
training_data <- X[indexes, ]
testing_data <- X[-indexes, ]
#split data y
y_nrow = nrow(Y)
y_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
y_training_data <- Y[y_splitIndex, ]
y_testing_data <- Y[-y_splitIndex, ]
#Using Model number one task 2.7
#training
training_ones=matrix(1,length(x_training_data)/4,1)
#split data x
set.seed(123)
x_nrow = nrow(X)
x_splitIndex <- sample(1:nrow(X), round(0.8 * nrow(X)))
# Split the data into training and testing datasets
x_training_data <- X[indexes, ]
x_testing_data <- X[-indexes, ]
#x_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
#x_splitIndex
#x_training_data <- X[x_splitIndex, ] x_testing_data <- X[-x_splitIndex, ]
#split data y
y_nrow = nrow(Y)
y_splitIndex <- sample(1:x_nrow, size = 0.7 * x_nrow , replace = FALSE)
y_training_data <- Y[y_splitIndex, ]
y_testing_data <- Y[-y_splitIndex, ]
#Using Model number one task 2.7
#training
training_ones=matrix(1,length(x_training_data)/4,1)
testing_ones=matrix(1,length(x_testing_data)/4,1)
#random noise
noise_training = rnorm(length(x_training_data)/4, 0, 0.1)
noise_testing = rnorm(length(x_testing_data)/4, 0, 0.1)
training_x = cbind(training_ones, (x_training_data[,"X4"]), (x_training_data[,"X1"])**3 , (x_training_data[,"X2"])**4 , (x_training_data[,"X1"])**4 , noise_training)
training_theta_hat = solve(t(training_x) %*% training_x) %*% t(training_x) %*% y_training_data
training_theta_hat
training_theta_hat = solve(t(training_x) %*% training_x) %*% t(training_x) %*% y_training_data
#Using Model number one task 2.7
#training
training_ones=matrix(1,length(x_training_data)/4,1)
testing_ones=matrix(1,length(x_testing_data)/4,1)
#random noise
noise_training = rnorm(length(x_training_data)/4, 0, 0.1)
noise_testing = rnorm(length(x_testing_data)/4, 0, 0.1)
training_x = cbind(training_ones, (x_training_data[,"X4"]), (x_training_data[,"X1"])**3 , (x_training_data[,"X2"])**4 , (x_training_data[,"X1"])**4 , noise_training)
training_theta_hat = solve(t(training_x) %*% training_x) %*% t(training_x) %*% y_training_data
testing_x = cbind(testing_ones, (x_testing_data[,"X4"]), (x_testing_data[,"X1"])**3 , (x_testing_data[,"X2"])**4 , (x_testing_data[,"X1"])**4 , noise_testing)
#Calculating Y-hat and Rss Model 1
testing_y_hat = testing_x %*% training_theta_hat
#for error bar calculation
conf_interval = t.test(y_training_data) #default 95% confidence interval
conf_interval_start = conf_interval$conf.int[1]
conf_interval_end = conf_interval$conf.int[2]
par(mar=c(5, 4, 4, 2) + 0.1)
plot(density(y_training_data), col="blue", lwd=2, main="Distribution of Traning Data",
xlab="Value", ylab="Density")
abline(v=conf_interval_start,col="red", lty=2)
abline(v=conf_interval_end,col="red", lty=2)
##Task 3
## Model 3 will be used, parameter are selected and kept constant.
rr_1=0
arr_2=0
f_value=0
s_value=0
Model3_thetahat
#values from thetahat
thetebias <- 0.448299550 #choosen parameter
thetaone <- 0.038109255 # chosen prarameter
thetatwo <- 0.009827804 # constant value
thetafour <- 0.002092558 # constant value
Epison <- RSS_Model_3 * 2 ## fixing value of eplision
num <- 100 #number of iteration
##Calculating Y-hat for performing rejection ABC
counter <- 0
for (i in 1:num) {
range1 <- runif(1,-0.448299550,0.448299550) # calculating the range
range1
range2 <- runif(1,-0.038109255,0.038109255)
New_thetahat <- matrix(c(range1,range2,thetatwo,thetafour))
New_Y_Hat <- X_model3 %*% New_thetahat ## New Y hat
new_RSS <- sum((Y-New_Y_Hat)^2)
new_RSS
if (new_RSS > Epison){
arr_1[i] <- range1
arr_2[i] <- range2
counter = counter+1
f_value <- matrix(arr_1)
s_value <- matrix(arr_2)
}
}
for (i in 1:num) {
range1 <- runif(1,-0.448299550,0.448299550) # calculating the range
range1
range2 <- runif(1,-0.038109255,0.038109255)
New_thetahat <- matrix(c(range1,range2,thetatwo,thetafour))
New_Y_Hat <- X_model3 %*% New_thetahat ## New Y hat
new_RSS <- sum((Y-New_Y_Hat)^2)
new_RSS
if (new_RSS > Epison){
arr_1[i] <- range1
arr_2[i] <- range2
counter = counter+1
f_value <- matrix(arr_1)
s_value <- matrix(arr_2)
}
}
for (i in 1:num) {
range1 <- runif(1,-0.448299550,0.448299550) # calculating the range
range1
range2 <- runif(1,-0.038109255,0.038109255)
New_thetahat <- matrix(c(range1,range2,thetatwo,thetafour))
New_Y_Hat <- X_model3 %*% New_thetahat ## New Y hat
new_RSS <- sum((Y-New_Y_Hat)^2)
new_RSS
if (new_RSS > Epison){
arr_1[i] <- range1
arr_2[i] <- range2
counter = counter+1
f_value <- matrix(arr_1)
s_value <- matrix(arr_2)
}
}
##Task 3
## Model 3 will be used, parameter are selected and kept constant.
arr_1=0
arr_2=0
f_value=0
s_value=0
Model3_thetahat
#values from thetahat
thetebias <- 0.448299550 #choosen parameter
thetaone <- 0.038109255 # chosen prarameter
thetatwo <- 0.009827804 # constant value
thetafour <- 0.002092558 # constant value
Epison <- RSS_Model_3 * 2 ## fixing value of eplision
num <- 100 #number of iteration
##Calculating Y-hat for performing rejection ABC
counter <- 0
for (i in 1:num) {
range1 <- runif(1,-0.448299550,0.448299550) # calculating the range
range1
range2 <- runif(1,-0.038109255,0.038109255)
New_thetahat <- matrix(c(range1,range2,thetatwo,thetafour))
New_Y_Hat <- X_model3 %*% New_thetahat ## New Y hat
new_RSS <- sum((Y-New_Y_Hat)^2)
new_RSS
if (new_RSS > Epison){
arr_1[i] <- range1
arr_2[i] <- range2
counter = counter+1
f_value <- matrix(arr_1)
s_value <- matrix(arr_2)
}
}
hist(f_value)
hist(s_value)
###ploting the graph
plot(f_value,s_value, col = c("red", "blue"), main = "Joint and Marginal Posterior Distribution")
